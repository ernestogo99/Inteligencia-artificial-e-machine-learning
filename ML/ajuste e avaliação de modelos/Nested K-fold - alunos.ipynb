{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested K-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrega os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de amostras: 1600\n",
      "Número de dimensões: 8\n",
      "Amostras por classe: (array([0, 1]), array([792, 808]))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, roc_curve, precision_recall_curve, auc, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "data = np.genfromtxt(\"californiabin.csv\", delimiter=',')\n",
    "x = data[:,:-1]\n",
    "y = data[:,-1].astype(int)\n",
    "\n",
    "print(f\"Número de amostras: {x.shape[0]}\")\n",
    "print(f\"Número de dimensões: {x.shape[1]}\")\n",
    "print(f\"Amostras por classe: {np.unique(y, return_counts=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_nested_cv(x, y, model_class, grid, external_kfold=5, internal_kfold=5, scale_flag=True, verbose=True, random_state=12345):\n",
    "    metrics = {'acc': [], 'rec': [], 'prec': [], 'f1': [], 'roc_auc': [], 'roc_curve': [], 'pr_auc': [], 'pr_curve': [], 'conf_mat': []}\n",
    "\n",
    "    # Escrevam o código!\n",
    "    \n",
    "    return metrics, best_model\n",
    "\n",
    "def inner_loop(x, y, model_class, grid, internal_kfold=10, scale_flag=True, verbose=True, random_state=12345):\n",
    "    param_names = list(grid.keys())\n",
    "    grid_search = np.meshgrid(*grid.values())\n",
    "    grid_search = np.hstack([ np.atleast_2d(g.ravel()).T for g in grid_search ], dtype='object')\n",
    "\n",
    "    # Escrevam o código!   \n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executa o grid-search para os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "external_kfold = 10\n",
    "internal_kfold = 5\n",
    "\n",
    "methods_summary = {'LR' : {'class': LogisticRegression, 'scale': True},\n",
    "                   'QDA': {'class': QuadraticDiscriminantAnalysis, 'scale': False},\n",
    "                   'GNB': {'class': GaussianNB, 'scale': False},\n",
    "                   'KNN': {'class': KNeighborsClassifier, 'scale': True},\n",
    "                   'DT' : {'class': DecisionTreeClassifier, 'scale': False}}\n",
    "\n",
    "# Logistic regression\n",
    "methods_summary['LR']['grid'] = {'solver' : ['liblinear'],\n",
    "                                'penalty': ['l1', 'l2'],                              # penalty\n",
    "                                'C': 1/np.array([0.00001, 0.0001, 0.001, 0.01, 0.1])} # C - inverse regularization\n",
    "\n",
    "# Quadratic Discriminant Analysis\n",
    "methods_summary['QDA']['grid'] = {'priors': None}\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "methods_summary['GNB']['grid'] = {'priors': None}\n",
    "\n",
    "# KNN\n",
    "methods_summary['KNN']['grid'] = {'n_neighbors': np.arange(1,12,2), # n_neighbors\n",
    "                                  'p': [1, 1.5, 2]}                 # p - Minkowski\n",
    "# Decision Tree\n",
    "methods_summary['DT']['grid'] = {'criterion': ['gini', 'entropy'],                # criterion\n",
    "                                 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, None]} # max_depth\n",
    "\n",
    "trained_models = {}\n",
    "for method, info in methods_summary.items():\n",
    "    print(f\"\\n[{method}] Running nested K-fold...\")\n",
    "    metrics, best_model = run_nested_cv(x=x, y=y, model_class=info['class'],\n",
    "                                        grid=info['grid'], scale_flag=info['scale'],\n",
    "                                        external_kfold=external_kfold, internal_kfold=internal_kfold)\n",
    "    trained_models[method] = {'metrics': metrics, 'model': best_model}\n",
    "\n",
    "\n",
    "# Results\n",
    "results = { method : {key: info['metrics'][key] for key in ['acc', 'rec', 'prec', 'f1', 'roc_auc', 'pr_auc']} for method, info in trained_models.items() }\n",
    "results_curves = { method : {key: info['metrics'][key] for key in ['roc_curve', 'pr_curve']} for method, info in trained_models.items() }\n",
    "results_conf_mats = { method : info['metrics']['conf_mat'] for method, info in trained_models.items() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela de resultados do Nested K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(results).T\n",
    "table[table.columns.difference(['roc_auc', 'pr_auc'])] = table[table.columns.difference(['roc_auc', 'pr_auc'])].map(lambda x: f\"{np.mean(x):.2%} +- {1.96*np.std(x)/np.sqrt(len(x)):.2%}\")\n",
    "table[['roc_auc', 'pr_auc']] = table[['roc_auc', 'pr_auc']].map(lambda x: f\"{np.mean(x):2.2f} +- {1.96*np.std(x)/np.sqrt(len(x)):2.2f}\")\n",
    "table.columns = ['Accuracy', 'Recall', 'Precision', 'F1-score', 'ROC-AUC', 'PR-AUC']\n",
    "table.index = results.keys()\n",
    "def extract_from_text(text):\n",
    "    return float(text.split('%')[0]) if '%' in text else float(text.split('+-')[0])\n",
    "table.style.apply(lambda col: [ 'font-weight:bold; color:red' if extract_from_text(x)==col.apply(extract_from_text).max() else '' for x in col ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curvas ROC/PRC médias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1+len(results_curves), 2, figsize=(10, (1+len(results_curves)) * 5))\n",
    "for i, (method, curves) in enumerate(results_curves.items()):\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    aucs = results[method]['roc_auc']\n",
    "    for curve in curves['roc_curve']:\n",
    "        fpr, tpr, t = curve\n",
    "        interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    std_tpr = np.std(tprs, axis=0) / np.sqrt(len(tprs))\n",
    "    tprs_upper = np.minimum(mean_tpr + 1.96*std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - 1.96*std_tpr, 0)\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs) / np.sqrt(len(aucs))\n",
    "\n",
    "    axs[-1,0].plot(mean_fpr, mean_tpr, label=fr'{method} (AUC = {mean_auc:0.2f} $\\pm$ {std_auc:0.2f})')\n",
    "    axs[-1,0].set_xlabel(\"FPR\")\n",
    "    axs[-1,0].set_ylabel(\"TPR\")\n",
    "    axs[-1,0].set_title(\"Mean ROC curves\")\n",
    "    axs[-1,0].legend()\n",
    "\n",
    "    axs[i,0].plot(mean_fpr, mean_tpr, color='blue', label=fr'Mean ROC (AUC = {mean_auc:0.2f} $\\pm$ {std_auc:0.2f})')\n",
    "    axs[i,0].fill_between(mean_fpr, tprs_lower, tprs_upper, color='blue', alpha=.2, label=r'$\\pm$ 1.96 std. error')\n",
    "    axs[i,0].set_xlabel(\"FPR\")\n",
    "    axs[i,0].set_ylabel(\"TPR\")\n",
    "    axs[i,0].set_title(f\"ROC curves over the outer folds - {method}\")\n",
    "    axs[i,0].legend()\n",
    "\n",
    "    mean_rec = np.linspace(0, 1, 100)\n",
    "    prcs = []\n",
    "    aucs = results[method]['pr_auc']\n",
    "    for curve in curves['pr_curve']:\n",
    "        prc, rec, t = curve\n",
    "        interp_prc = np.interp(mean_rec, rec[::-1], prc[::-1])\n",
    "        prcs.append(interp_prc)\n",
    "        aucs.append(auc(rec[::-1], prc[::-1]))\n",
    "\n",
    "    mean_prc = np.mean(prcs, axis=0)\n",
    "    std_prc = np.std(prcs, axis=0) / np.sqrt(len(prcs))\n",
    "    prcs_upper = np.minimum(mean_prc + 1.96*std_prc, 1)\n",
    "    prcs_lower = np.maximum(mean_prc - 1.96*std_prc, 0)\n",
    "    mean_auc = auc(mean_rec, mean_prc)\n",
    "    std_auc = np.std(aucs) / np.sqrt(len(aucs))\n",
    "\n",
    "    axs[-1,1].plot(mean_rec, mean_prc, label=fr'{method} (AUC = {mean_auc:0.2f} $\\pm$ {std_auc:0.2f})')\n",
    "    axs[-1,1].set_xlabel(\"Recall\")\n",
    "    axs[-1,1].set_ylabel(\"Precision\")\n",
    "    axs[-1,1].set_title(\"Mean PR curves\")\n",
    "    axs[-1,1].legend()\n",
    "\n",
    "    axs[i,1].plot(mean_rec, mean_prc, color='blue', label=fr'Mean PRC (AUC = {mean_auc:0.2f} $\\pm$ {std_auc:0.2f})')\n",
    "    axs[i,1].fill_between(mean_rec, prcs_lower, prcs_upper, color='blue', alpha=.2, label=r'$\\pm$ 1.96 std. error')\n",
    "    axs[i,1].set_xlabel(\"Recall\")\n",
    "    axs[i,1].set_ylabel(\"Precision\")\n",
    "    axs[i,1].set_title(f\"PR curves over the outer folds - {method}\")\n",
    "    axs[i,1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrizes de confusão médias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (method, conf_mat) in enumerate(results_conf_mats.items()):\n",
    "    ConfusionMatrixDisplay(np.mean(conf_mat, axis=0)).plot(values_format=\".1%\")\n",
    "    plt.title(f\"Average confusion matrix over the outer folds - {method}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
